import base64
from typing import Dict, Any
from llama_index.llms.azure_openai import AzureOpenAI
from llama_index.core.schema import Document, MediaResource
from llama_index.core.llms import ChatMessage, ImageBlock, TextBlock, MessageRole
from llama_index.core.tools import BaseTool, FunctionTool
from prompts.prompts import description_prompt, legal_prompt, clarifications_prompt, consistency_prompt, raw_text_extraction_prompt
from raptor.raptor_setup import RaptorSetup
from datetime import datetime
from utils.output_saver import OutputSaver
from utils.text_extractor import TextExtractor
import os
from pathlib import Path

class Tools:
    """Collection des outils disponibles pour l'analyse de publicit√©"""
    def __init__(self, llm: AzureOpenAI, raptor: RaptorSetup):
        self.llm = llm
        self.raptor = raptor
        self._tools = self._create_tools()
        self.vision_result = None
        self.legislation = None
        self.raw_text = None
        self.output_saver = OutputSaver()
        self.text_extractor = TextExtractor()
        self.extracted_text = None
    
    def _create_tools(self) -> list[BaseTool]:
        """Cr√©e la liste des outils disponibles pour l'agent"""
        return [
            FunctionTool.from_defaults(
                fn=self.extract_raw_text_for_agent,
                name="extract_raw_text",
                description="Extrait le texte brut d'une image publicitaire sans aucune modification ou correction. √Ä utiliser en PREMIER, avant toute autre analyse.",
            ),
            FunctionTool.from_defaults(
                fn=self.analyze_vision,
                name="analyze_vision",
                description="Analyse une image publicitaire et fournit une description d√©taill√©e structur√©e. Utilisez cet outil APR√àS l'extraction du texte brut.",
            ),
            FunctionTool.from_defaults(
                fn=self.verify_consistency,
                name="verify_consistency",
                description="V√©rifie la coh√©rence des informations (orthographe, adresse, t√©l√©phone, email, url) apr√®s l'analyse visuelle.",
            ),
            FunctionTool.from_defaults(
                fn=self.verify_dates,
                name="verify_dates",
                description="V√©rifie la coh√©rence des dates et des jours de la semaine mentionn√©s dans la publicit√©. V√©rifie √©galement si les dates sont futures ou pass√©es.",
            ),
            FunctionTool.from_defaults(
                fn=self.search_legislation,
                name="search_legislation",
                description="Recherche la l√©gislation applicable en fonction de la description de l'image. √Ä utiliser apr√®s analyze_vision.",
            ),
            FunctionTool.from_defaults(
                fn=self.get_clarifications,
                name="get_clarifications",
                description="Obtient des clarifications sp√©cifiques sur des aspects de la publicit√© en se basant sur la vision et la l√©gislation.",
            ),
            FunctionTool.from_defaults(
                fn=self.analyze_compliance,
                name="analyze_compliance",
                description="Analyse finale de la conformit√© de la publicit√© en combinant tous les r√©sultats pr√©c√©dents.",
            ),
        ]
    
    @property
    def tools(self) -> list[BaseTool]:
        """Retourne la liste des outils disponibles"""
        return self._tools

    def analyze_vision(self, image_path: str) -> str:
        """
        Analyse une image publicitaire avec GPT-4V
        Args:
            image_path: Chemin vers l'image √† analyser
        Returns:
            str: Description d√©taill√©e structur√©e de l'image
        """
        print(f"\nüñºÔ∏è Analyse de l'image: {image_path}")
        
        # V√©rifier si l'analyse a d√©j√† √©t√© initialis√©e (par l'extraction de texte brut)
        if not self.output_saver.is_analysis_in_progress():
            self.output_saver.start_new_analysis(image_path)
        
        with open(image_path, "rb") as image_file:
            img_data = base64.b64encode(image_file.read())
        
        self._last_image_data = img_data  # Garder l'image en m√©moire
        image_document = Document(image_resource=MediaResource(data=img_data))
        
        # Pr√©parer un prompt qui inclut le texte brut d√©j√† extrait
        enhanced_prompt = description_prompt
        if hasattr(self, 'raw_text') and self.raw_text:
            enhanced_prompt = f"""Le texte brut suivant a d√©j√† √©t√© extrait de l'image. Utilisez-le comme r√©f√©rence pour votre analyse mais NE LE RECOPIEZ PAS int√©gralement:

TEXTE BRUT D√âJ√Ä EXTRAIT:
----------
{self.raw_text}
----------

{description_prompt}"""
        
        msg = ChatMessage(
            role=MessageRole.USER,
            blocks=[
                TextBlock(text=enhanced_prompt),
                ImageBlock(image=image_document.image_resource.data),
            ],
        )

        response = self.llm.chat(messages=[msg])
        result = str(response)
        
        # Supprimer le pr√©fixe "assistant:" s'il est pr√©sent
        if result.startswith("assistant:"):
            result = result[len("assistant:"):].strip()
            
        self.vision_result = result
        
        self.output_saver.save_vision_result(self.vision_result)
        
        return self.vision_result

    def verify_consistency(self, vision_result: str) -> str:
        """
        V√©rifie la coh√©rence des informations extraites de l'image
        
        Args:
            vision_result: R√©sultat de l'analyse visuelle
            
        Returns:
            str: Rapport de v√©rification de coh√©rence
        """
        print("\nüîç V√©rification de la coh√©rence des informations...")
        
        if not self.vision_result:
            raise ValueError("L'analyse visuelle doit √™tre effectu√©e d'abord")
        
        # Obtenir la date actuelle au format fran√ßais
        current_date = datetime.now().strftime("%d/%m/%Y")
        
        # Pr√©parer un prompt qui inclut le texte brut d√©j√† extrait
        enhanced_prompt = consistency_prompt.format(
            vision_result=vision_result,
            current_date=current_date
        )
        
        if hasattr(self, 'raw_text') and self.raw_text:
            enhanced_prompt = f"""Le texte brut suivant a d√©j√† √©t√© extrait de l'image. Utilisez-le comme r√©f√©rence pour votre v√©rification de coh√©rence:

TEXTE BRUT D√âJ√Ä EXTRAIT:
----------
{self.raw_text}
----------

{consistency_prompt.format(vision_result=vision_result, current_date=current_date)}"""
        
        msg = ChatMessage(
            role=MessageRole.USER,
            blocks=[
                TextBlock(text=enhanced_prompt),
                ImageBlock(image=self._last_image_data),
            ],
        )
        
        response = self.llm.chat(messages=[msg])
        result = str(response)
        
        # Supprimer le pr√©fixe "assistant:" s'il est pr√©sent
        if result.startswith("assistant:"):
            result = result[len("assistant:"):].strip()
        
        self.output_saver.save_consistency_check(result)
        
        return result

    def verify_dates(self, vision_result: str = None) -> str:
        """
        V√©rifie la coh√©rence des dates mentionn√©es dans la publicit√©
        
        Args:
            vision_result: R√©sultat de l'analyse visuelle (optionnel)
            
        Returns:
            str: Rapport de v√©rification des dates
        """
        print("\nüìÖ V√©rification de la coh√©rence des dates...")
        
        if not vision_result and not self.vision_result:
            raise ValueError("L'analyse visuelle doit √™tre effectu√©e d'abord")
            
        vision_content = vision_result if vision_result else self.vision_result
        
        # Obtenir la date actuelle au format fran√ßais
        current_date = datetime.now().strftime("%d/%m/%Y")
        
        prompt = f"""V√âRIFICATION DE LA COH√âRENCE DES DATES

Date actuelle : {current_date}

CONTENU √Ä ANALYSER :
{vision_content}

INSTRUCTIONS :
1. Extraire toutes les dates et jours de la semaine mentionn√©s dans la publicit√©
2. Pour chaque date au format JJ/MM/AAAA ou similaire :
   - V√©rifier si elle correspond bien au jour de la semaine mentionn√© (ex: "vendredi 08/03/2025")
   - V√©rifier si la date est future ou pass√©e par rapport √† aujourd'hui ({current_date})
   - V√©rifier la coh√©rence entre les p√©riodes (dates de d√©but et de fin)
   - V√©rifier si les jours f√©ri√©s sont correctement mentionn√©s
3. Pour chaque jour de la semaine mentionn√© sans date pr√©cise :
   - Indiquer les dates possibles dans un futur proche (prochaines occurrences)

TEXTE BRUT (pour r√©f√©rence) :
{self.raw_text if hasattr(self, 'raw_text') and self.raw_text else "Non disponible"}

FORMAT DE R√âPONSE :
DATES IDENTIFI√âES :
- Date 1 : [format original] => [JJ/MM/AAAA] [jour de la semaine] [future/pass√©e] [coh√©rente/non coh√©rente avec le jour mentionn√©]
- Date 2 : [format original] => [JJ/MM/AAAA] [jour de la semaine] [future/pass√©e] [coh√©rente/non coh√©rente avec le jour mentionn√©]

P√âRIODES IDENTIFI√âES :
- P√©riode 1 : Du [date d√©but] au [date fin] => [dur√©e en jours] [coh√©rente/non coh√©rente]
- P√©riode 2 : Du [date d√©but] au [date fin] => [dur√©e en jours] [coh√©rente/non coh√©rente]

JOURS DE LA SEMAINE SANS DATE PR√âCISE :
- [Jour mentionn√©] => Prochaines occurrences : [dates]

INCOH√âRENCES D√âTECT√âES :
- [Description pr√©cise de chaque incoh√©rence]

RECOMMANDATIONS :
- [Suggestions pour corriger les incoh√©rences]

VERDICT DE COH√âRENCE TEMPORELLE : [COH√âRENT/NON COH√âRENT/PARTIELLEMENT COH√âRENT]
"""
        
        # Utiliser le LLM pour analyser les dates
        response = self.llm.complete(prompt)
        result = str(response)
        
        # Supprimer le pr√©fixe "assistant:" s'il est pr√©sent
        if result.startswith("assistant:"):
            result = result[len("assistant:"):].strip()
        
        # Sauvegarder le r√©sultat
        # La m√©thode save_dates_verification n'existe pas encore, nous devons l'ajouter √† OutputSaver
        if hasattr(self.output_saver, 'save_dates_verification'):
            self.output_saver.save_dates_verification(result)
        else:
            # Si la m√©thode n'existe pas, on utilise save_custom_data ou on affiche un avertissement
            print("‚ö†Ô∏è La m√©thode save_dates_verification n'existe pas dans OutputSaver")
        
        return result

    def search_legislation(self, vision_result: str) -> str:
        """
        Recherche la l√©gislation applicable
        Args:
            vision_result: R√©sultat de l'analyse visuelle
        Returns:
            str: L√©gislation applicable
        """
        print("\nüîç Recherche de l√©gislation...")
        print(f"Vision result utilis√© pour la recherche: {vision_result[:200]}...")
        
        try:
            # Rechercher dans la base de connaissances
            raw_legislation = self.raptor.search(vision_result)
            print(f"\nL√©gislation brute trouv√©e: {raw_legislation[:200]}...")
            
            # Stocker la l√©gislation brute
            self.legislation = raw_legislation
            
            # Utiliser le query engine pour synth√©tiser la r√©ponse
            query = f"""Analyser et synth√©tiser la l√©gislation suivante dans le contexte de cette publicit√© :
            
            CONTEXTE PUBLICITAIRE :
            {vision_result}
            
            L√âGISLATION TROUV√âE :
            {raw_legislation}
            """
            
            synthesis = self.raptor.query(query)
            print(f"\nSynth√®se de la l√©gislation: {synthesis[:200]}...")
            
            self.output_saver.save_legislation(synthesis)
            
            return synthesis
            
        except Exception as e:
            print(f"\n‚ùå Erreur lors de la recherche de l√©gislation: {str(e)}")
            # En cas d'erreur, utiliser la l√©gislation brute si disponible
            if raw_legislation:
                return raw_legislation
            raise

    def get_clarifications(self, questions_text: str) -> str:
        """
        Obtient des clarifications sp√©cifiques en analysant l'image
        Args:
            questions_text: Questions sp√©cifiques n√©cessitant des clarifications
        Returns:
            str: R√©ponses aux questions de clarification
        """
        print("\n‚ùì Obtention des clarifications...")
        
        if not self.vision_result or not self.legislation:
            raise ValueError("L'analyse visuelle et la recherche de l√©gislation doivent √™tre effectu√©es d'abord")
        
        # Initialiser l'historique des clarifications si n√©cessaire
        if not hasattr(self, '_clarifications_history'):
            self._clarifications_history = set()
        
        # V√©rifier si la question a d√©j√† √©t√© pos√©e
        if questions_text in self._clarifications_history:
            print("‚ö†Ô∏è Cette clarification a d√©j√† √©t√© demand√©e")
            return "Cette question a d√©j√† √©t√© pos√©e. Veuillez demander des clarifications sur d'autres aspects ou passer √† l'analyse de conformit√©."
        
        # Ajouter la question √† l'historique
        self._clarifications_history.add(questions_text)
        
        # Cr√©er le message multimodal avec l'image
        msg = ChatMessage(
            role=MessageRole.USER,
            blocks=[
                TextBlock(text=clarifications_prompt.format(questions_text=questions_text)),
                ImageBlock(image=self._last_image_data),
            ],
        )
        
        print("\nEnvoi de l'image et des questions au LLM...")
        response = self.llm.chat(messages=[msg])
        result = str(response)
        
        # Supprimer le pr√©fixe "assistant:" s'il est pr√©sent
        if result.startswith("assistant:"):
            result = result[len("assistant:"):].strip()
        
        self.output_saver.save_clarifications(result)
        
        return result

    def analyze_compliance(self) -> str:
        """
        Analyse finale de la conformit√©
        Returns:
            str: Analyse compl√®te de la conformit√©
        """
        if not self.vision_result or not self.legislation:
            raise ValueError("Toutes les √©tapes pr√©c√©dentes doivent √™tre compl√©t√©es")
            
        prompt = legal_prompt.format(description=self.vision_result)
        response = self.llm.complete(prompt)
        result = str(response)
        
        # Supprimer le pr√©fixe "assistant:" s'il est pr√©sent
        if result.startswith("assistant:"):
            result = result[len("assistant:"):].strip()
        
        self.output_saver.save_compliance_analysis(result)
        
        return result

    def extract_text_from_image(self, image_path: str, mode: str = "docling", ocr_engine: str = "tesseract") -> str:
        """
        Extrait le texte visible dans une image publicitaire
        
        Args:
            image_path: Chemin vers l'image √† analyser
            mode: Mode d'extraction ('docling', 'pytesseract', 'easyocr')
            ocr_engine: Moteur OCR √† utiliser avec Docling ('tesseract', 'easyocr', 'rapidocr')
            
        Returns:
            str: Texte extrait de l'image
        """
        print(f"\nüî§ Extraction du texte de l'image avec {mode}: {image_path}")
        
        # Configurer les options d'extraction selon le mode
        options = {}
        if mode == "docling":
            try:
                # Options avanc√©es pour l'extraction Docling
                extracted_text = self.text_extractor.extract_text_with_docling(
                    image_path, 
                    ocr_engine=ocr_engine,
                    custom_options=options
                )
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur avec Docling: {str(e)}. Essai d'une m√©thode alternative...")
                # Fallback vers une autre m√©thode
                extracted_text = self.text_extractor.extract_text(image_path, fallback=True)
        elif mode == "pytesseract":
            extracted_text = self.text_extractor.extract_text_with_pytesseract(image_path)
        elif mode == "easyocr":
            extracted_text = self.text_extractor.extract_text_with_easyocr_direct(image_path)
        else:
            print(f"‚ö†Ô∏è Mode {mode} non support√©, utilisation de la m√©thode g√©n√©rique")
            extracted_text = self.text_extractor.extract_text(image_path, fallback=True)
        
        # Si le texte est vide, afficher un avertissement
        if not extracted_text or len(extracted_text.strip()) < 5:
            print("‚ö†Ô∏è Attention: Tr√®s peu ou pas de texte extrait de l'image.")
        else:
            print(f"‚úÖ Texte extrait ({len(extracted_text)} caract√®res)")
            
        # Sauvegarder des m√©tadonn√©es suppl√©mentaires pour l'analyse
        metadata = {
            "mode": mode,
            "ocr_engine": ocr_engine if mode == "docling" else "N/A",
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "char_count": len(extracted_text),
            "success": bool(extracted_text and len(extracted_text.strip()) > 5)
        }
        
        # Sauvegarder le r√©sultat dans les sorties
        self.output_saver.save_text_extraction(extracted_text, mode)
        self.extracted_text = extracted_text
        
        return extracted_text 

    def extract_raw_text_with_vision(self, image_path: str) -> str:
        """
        Utilise GPT Vision pour extraire le texte brut d'une image sans aucune correction orthographique
        
        Args:
            image_path: Chemin vers l'image √† analyser
            
        Returns:
            str: Texte brut extrait
        """
        print(f"\nüîç Extraction de texte brut avec GPT Vision: {image_path}")
        
        # V√©rifier que l'image existe
        if not os.path.exists(image_path):
            print(f"‚ùå Image non trouv√©e: {image_path}")
            return ""
        
        # Charger l'image en base64
        with open(image_path, "rb") as image_file:
            img_data = base64.b64encode(image_file.read())
        
        # Cr√©er le document d'image
        image_document = Document(image_resource=MediaResource(data=img_data))
        
        # Cr√©er un message multimodal avec l'image et la demande d'extraction de texte brut
        msg = ChatMessage(
            role=MessageRole.USER,
            blocks=[
                TextBlock(text=raw_text_extraction_prompt),
                ImageBlock(image=image_document.image_resource.data),
            ],
        )
        
        # Envoyer la demande √† GPT Vision
        try:
            response = self.llm.chat(messages=[msg])
            extracted_text = str(response)
            
            # Supprimer le pr√©fixe "assistant:" s'il est pr√©sent
            if extracted_text.startswith("assistant:"):
                extracted_text = extracted_text[len("assistant:"):].strip()
            
            # Sauvegarder le r√©sultat
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_dir = Path("outputs") / "raw_text"
            output_dir.mkdir(parents=True, exist_ok=True)
            output_file = output_dir / f"{Path(image_path).stem}_gpt_vision_{timestamp}.txt"
            
            with open(output_file, "w", encoding="utf-8") as f:
                f.write(extracted_text)
            
            print(f"üíæ Texte brut sauvegard√©: {output_file}")
            
            return extracted_text
            
        except Exception as e:
            print(f"‚ùå Erreur lors de l'extraction de texte avec GPT Vision: {str(e)}")
            return f"ERREUR: {str(e)}"

    def extract_raw_text_for_agent(self, image_path: str) -> str:
        """
        Extrait le texte brut d'une image publicitaire pour l'agent ReACT
        
        Args:
            image_path: Chemin vers l'image √† analyser
            
        Returns:
            str: Texte brut extrait
        """
        print(f"\nüìù Extraction du texte brut pour l'agent: {image_path}")
        
        try:
            # V√©rifier que l'image existe
            if not os.path.exists(image_path):
                error_msg = f"‚ùå Image non trouv√©e: {image_path}"
                print(error_msg)
                return error_msg
            
            # Initialiser une nouvelle analyse - Important: doit √™tre fait AVANT d'essayer de sauvegarder des r√©sultats
            self.output_saver.start_new_analysis(image_path)
            
            # Utiliser GPT Vision pour l'extraction
            result = self.extract_raw_text_with_vision(image_path)
            
            # V√©rifier que le r√©sultat n'est pas vide
            if not result or len(result.strip()) < 10:
                print("‚ö†Ô∏è Texte extrait trop court ou vide, mais continuons l'analyse")
            
            # Sauvegarder dans les donn√©es de l'analyse
            self.raw_text = result
            
            # Sauvegarder dans l'output_saver
            self.output_saver.save_raw_text(result)
            
            print("‚úÖ Extraction de texte brut r√©ussie")
            return result
            
        except Exception as e:
            error_msg = f"‚ùå Erreur lors de l'extraction du texte brut: {str(e)}"
            print(error_msg)
            # M√™me en cas d'erreur, on continue l'analyse
            print("‚ö†Ô∏è Continuez avec l'analyse visuelle malgr√© l'erreur d'extraction")
            return error_msg 